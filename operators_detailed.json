[
  {
    "name": "add",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "add(x, y, filter = false), x + y",
    "description": "Add all inputs (at least 2 inputs required). If filter = true, filter all input NaN to 0 before adding",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "multiply",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "multiply(x ,y, ... , filter=false), x * y",
    "description": "Multiply all inputs. At least 2 inputs are required. Filter sets the NaN values to 1",
    "documentation": "/operators/multiply",
    "level": "ALL",
    "summary": "**Examples** :  \nAlpha Expression:\nmultiply(rank(-returns),rank(volume/adv20),filter=true)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: INDUSTRY\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "sign",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "sign(x)",
    "description": "if input = NaN; return NaN",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "subtract",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "subtract(x, y, filter=false), x - y",
    "description": "x-y. If filter = true, filter all input NaN to 0 before subtracting",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "log",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "log(x)",
    "description": "Natural logarithm. For example: Log(high/low) uses natural logarithm of high/low ratio as stock weights.",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "max",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "max(x, y, ..)",
    "description": "Maximum value of all inputs. At least 2 inputs are required",
    "documentation": "/operators/max",
    "level": "ALL",
    "summary": "**Example:**  \nAlpha Expression:\nmax(close,vwap)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 2\nNeutralization: INDUSTRY\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "abs",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "abs(x)",
    "description": "Absolute value of x",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "divide",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "divide(x, y), x / y",
    "description": "x / y",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "min",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "min(x, y ..)",
    "description": "Minimum value of all inputs. At least 2 inputs are required",
    "documentation": "/operators/min",
    "level": "ALL",
    "summary": "**Example:**  \nAlpha Expression:\nmin(close,vwap)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: INDUSTRY\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "signed_power",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "signed_power(x, y)",
    "description": "x raised to the power of y such that final result preserves sign of x",
    "documentation": "/operators/signed_power",
    "level": "ALL",
    "summary": "**sign(x) * (abs(x) ^ y)**   x raised to the power of y such that final result preserves sign of x. For power of 2, x ^ y will be a parabola but signed_power(x, y) will be odd and one-to-one function (unique value of x for certain value of signed_power(x, y)) unlike parabola.  \n**Example:**   If x = 3, y = 2 \u21d2 abs(x) = 3 \u21d2 abs(x) ^ y = 9 and sign(x) = +1 \u21d2 sign(x) * (abs(x) ^ y) = signed_power(x, y) = 9   If x = -9, y = 0.5 \u21d2 abs(x) = 9 \u21d2 abs(x) ^ y = 3 and sign(x) = -1 \u21d2 sign(x) * (abs(x) ^ y) = signed_power(x, y)  \n"
  },
  {
    "name": "inverse",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "inverse(x)",
    "description": "1 / x",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "sqrt",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "sqrt(x)",
    "description": "Square root of x",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "reverse",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "reverse(x)",
    "description": "\u00a0- x",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "power",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "power(x, y)",
    "description": "x ^ y",
    "documentation": "/operators/power",
    "level": "ALL",
    "summary": "Alpha Expression:\npower(returns,volume/adv20);power(returns,volume/adv20,precise=true)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: INDUSTRY\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\npower (x, y) operator can be used to implement popular mathematical functions. For example, sigmoid(close) can be implemented using power(x) as:  \nAlpha Expression:\n1/(1+power(2.7182,-close)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 1\nNeutralization: MARKET\nTruncation: 1.0\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "densify",
    "category": "Arithmetic",
    "scope": [
      "REGULAR"
    ],
    "definition": "densify(x)",
    "description": "Converts a grouping field of many buckets into lesser number of only available buckets so as to make working with grouping fields computationally efficient",
    "documentation": "/operators/densify",
    "level": "ALL",
    "summary": "This operator converts a grouping field with many buckets into a lesser number of only the available buckets, making working with grouping fields computationally efficient. The example below will clarify the implementation.  **Example:**  Say a grouping field is provided as an integer (e.g., industry: tech -> 0, airspace -> 1, ...) and for a certain date, we have instruments with grouping field values among {0, 1, 2, 99}. Instead of creating 100 buckets and keeping 96 of them empty, it is better to just create 4 buckets with values {0, 1, 2, 3}. So, if the number of unique values in x is n, densify maps those values between 0 and (n-1). The order of magnitude need not be preserved.  \n"
  },
  {
    "name": "or",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "or(input1, input2)",
    "description": "Logical OR operator returns true if either or both inputs are true and returns false otherwise",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "and",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "and(input1, input2)",
    "description": "Logical AND operator, returns true if both operands are true and returns false otherwise",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "not",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "not(x)",
    "description": "Returns the logical negation of x. If x is true (1), it returns false (0), and if input is false (0), it returns true (1).",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "is_nan",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "is_nan(input)",
    "description": "If (input == NaN) return 1 else return 0",
    "documentation": "/operators/is_nan",
    "level": "ALL",
    "summary": "is_nan(x) operator can be used to identify NaN values and replace them to a default value using if_else statement. For example:  \nAlpha Expression:\nif_else(is_nan(rank(sales)),0.5,rank(sales))\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 1\nNeutralization: MARKET\nTruncation: 1.0\nPasteurization: ON\nNaN Handling: OFF\nIn this example, in case sales value is NaN for any instrument, then the expression will replace it with the mean value of rank, that is 0.5.  \n"
  },
  {
    "name": "less",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "input1 < input2",
    "description": "If input1 < input2 return true, else return false",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "equal",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "input1 == input2",
    "description": "Returns true if both inputs are same and returns false otherwise",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "greater",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "input1 > input2",
    "description": "Logic comparison operators to compares two inputs",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "if_else",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "if_else(input1, input2, input 3)",
    "description": "If input1 is true then return input2 else return input3.",
    "documentation": "/operators/if_else",
    "level": "ALL",
    "summary": "**if_else(event_condition, Alpha_expression_1, Alpha_expression_2)**  \nIf the event condition provided is true, Alpha_expression_1 will be returned. If the event condition provided is false, Alpha_expression_2 will be returned.  **Example:**  We are interested in testing our hypothesis that if the stock price of a company has increased over the last 2 days, it may decrease in the future. Also, if the number of stocks bought and sold today is higher than the monthly average, then the reversion effect may be observed more profoundly.  We will implement this hypothesis by taking positions according to the difference of close price today and 3 days ago with alpha_2 using the ts_delta operator. When current volume is higher than average daily volume, we will take a larger position by multiplying by 2 to get alpha_1.  \nAlpha Expression:\nEvent=volume>adv20;alpha_1=2*(-ts_delta(close,3));alpha_2=(-ts_delta(close,3));if_else(event,alpha_1,alpha_2)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: INDUSTRY\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "not_equal",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "input1!= input2",
    "description": "Returns true if both inputs are NOT the same and returns false otherwise",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "less_equal",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "input1 <= input2",
    "description": "Returns true if input1 <= input2, return false otherwise",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "greater_equal",
    "category": "Logical",
    "scope": [
      "REGULAR"
    ],
    "definition": "input1 >= input2",
    "description": "Returns true if input1 >= input2, return false otherwise",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_corr",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_corr(x, y, d)",
    "description": "Returns correlation of x and y for the past d days",
    "documentation": "/operators/ts_corr",
    "level": "ALL",
    "summary": "**ts_corr(x, y, d)**  Pearson correlation measures the linear relationship between two variables. It's most effective when the variables are normally distributed and the relationship is linear.  \n**Example:**  \nAlpha Expression:\nts_corr(vwap,close,20)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: INDUSTRY\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "ts_zscore",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_zscore(x, d)",
    "description": "Z-score is a numerical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean: (x - tsmean(x,d)) / tsstddev(x,d). This operator may help reduce outliers and drawdown.",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_product",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_product(x, d)",
    "description": "Returns product of x for the past d days",
    "documentation": "/operators/ts_product",
    "level": "ALL",
    "summary": "ts_product(x, d) can be used to calculate geometric mean of data fields. The geometric mean is generally a better method for averaging rates of return, growth rates of fundamentals. For example, geometric mean of daily stock returns for past 10 days can be calculated as:  \nAlpha Expression:\npower(ts_product(returns,10),1/10)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 1\nNeutralization: MARKET\nTruncation: 1.0\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "ts_std_dev",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_std_dev(x, d)",
    "description": "Returns standard deviation of x for the past d days",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_backfill",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_backfill(x,lookback = d, k=1, ignore=\"NAN\")",
    "description": "Backfill is the process of replacing the NAN or 0 values by a meaningful value (i.e., a first non-NaN value)",
    "documentation": "/operators/ts_backfill",
    "level": "ALL",
    "summary": "ts_backfill(x,lookback = d, k=1, ignore=\"NAN\")  The ts_backfill operator replaces NaN values with the last available non-NaN value. If the input value of the data field x is NaN, the ts_backfill operator will check available input values of the same data field for the past d number of days, and output the most recent available non-NaN input value. If the k parameter is set, then the ts_backfill operator will output the kth most recent available non-NaN input value.  This operator improves weight coverage and may help to reduce drawdown risk.  **Example:** ts_backfill(x, 252)    * If the input value for data field x = non-NaN, then output = x   * If the input value for data field x = NaN, then output = most recent available non-NaN input value for x in the past 252 days  \n"
  },
  {
    "name": "days_from_last_change",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "days_from_last_change(x)",
    "description": "Amount of days since last change of x",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "last_diff_value",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "last_diff_value(x, d)",
    "description": "Returns last x value not equal to current x value from last d days",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_scale",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_scale(x, d, constant = 0)",
    "description": "Returns (x - ts_min(x, d)) / (ts_max(x, d) - ts_min(x, d)) + constant. This operator is similar to scale down operator but acts in time series space",
    "documentation": "/operators/ts_scale",
    "level": "ALL",
    "summary": "This operator returns (x \u2013 ts_min(x, d)) / (ts_max(x, d) \u2013 ts_min(x, d)) + constant   This operator is similar to scale down operator but acts in time series space    **Example:**   If d = 6 and values for last 6 days are [6,2,8,5,9,4] with first element being today\u2019s value, ts_min(x,d) = 2, ts_max(x,d) = 9   ts_scale(x,d,constant = 1) = 1 + (6-2)/(9-2) = 1.57  \n"
  },
  {
    "name": "ts_step",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_step(1)",
    "description": "Returns days' counter",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_sum",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_sum(x, d)",
    "description": "Sum values of x for the past d days.",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_av_diff",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_av_diff(x, d)",
    "description": "Returns x - tsmean(x, d), but deals with NaNs carefully. That is NaNs are ignored during mean computation",
    "documentation": "/operators/ts_av_diff",
    "level": "ALL",
    "summary": "This operator returns x \u2013 ts_mean(x, d), but it deals with NaNs carefully    **Example:**   If d = 6 and values for past 6 days are [6,2,8,5,9,NaN] then ts_mean(x,d) = 6 since NaN are ignored from mean computation. Hence, ts_av_diff(x,d) = 6-6 = 0  \n"
  },
  {
    "name": "ts_mean",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_mean(x, d)",
    "description": "Returns average value of x for the past d days.",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_arg_max",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_arg_max(x, d)",
    "description": "Returns the relative index of the max value in the time series for the past d days. If the current day has the max value for the past d days, it returns 0. If previous day has the max value for the past d days, it returns 1",
    "documentation": "/operators/ts_arg_max",
    "level": "ALL",
    "summary": "It returns the relative index of the max value in the time series for the past d days. If the current day has the max value for the past d days, it returns 0. If previous day has the max value for the past d days, it returns 1.    **Example:**   If d = 6 and values for past 6 days are [6,2,8,5,9,4] with first element being today\u2019s value then max value is 9 and it is present 4 days before today. Hence, ts_arg_max(x, d) = 4  \n"
  },
  {
    "name": "ts_rank",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_rank(x, d, constant = 0)",
    "description": "Rank the values of x for each instrument over the past d days, then return the rank of the current value + constant. If not specified, by default, constant = 0.",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_delay",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_delay(x, d)",
    "description": "Returns x value d days ago",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_quantile",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_quantile(x,d, driver=\"gaussian\" )",
    "description": "It calculates ts_rank and apply to its value an inverse cumulative density function from driver distribution. Possible values of driver (optional ) are \"gaussian\", \"uniform\", \"cauchy\" distribution where \"gaussian\" is the default.",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_count_nans",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_count_nans(x ,d)",
    "description": "Returns the number of NaN values in x for the past d days",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_covariance",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_covariance(y, x, d)",
    "description": "Returns covariance of y and x for the past d days",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "ts_decay_linear",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_decay_linear(x, d, dense = false)",
    "description": "Returns the linear decay on x for the past d days. Dense parameter=false means operator works in sparse mode and we treat NaN as 0. In dense mode we do not.",
    "documentation": "/operators/ts_decay_linear",
    "level": "ALL",
    "summary": "ts_decay_linear(x, d, dense = false)  Returns the linear decay on x for the past d days. Dense parameter=false means operator works in sparse mode and we treat NaN as 0. In dense mode we do not. Data smoothing techniques like linear decay reduce noise in time-series data by applying a decay factor to older observations, which helps to stabilize the dataset.  This operator improves turnover and drawdown.  **Example:**    * For a stock with the following prices over the last 5 days:     * Day 0: 30 (outlier)     * Day -1: 5     * Day -2: 4     * Day -3: 5     * Day -4: 6   * The calculation would be:     * Numerator = (30\u22c55)+(5\u22c54)+(4\u22c53)+(5\u22c52)+(6\u22c51)=150+20+12+10+6=198     * Denominator=5+4+3+2+1=15     * Weighted Average=198/15=13.2   * The weighted average value of 13.2 is used instead of the outlier value of 20 for assigning weight.  \n"
  },
  {
    "name": "ts_arg_min",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_arg_min(x, d)",
    "description": "Returns the relative index of the min value in the time series for the past d days; If the current day has the min value for the past d days, it returns 0; If previous day has the min value for the past d days, it returns 1.",
    "documentation": "/operators/ts_arg_min",
    "level": "ALL",
    "summary": "ts_arg_min(x, d)  It returns the relative index of the min value in the time series for the past d days. If the current day has the min value for the past d days, it returns 0. If previous day has the min value for the past d days, it returns 1.    **Example:**   If d = 6 and values for past 6 days are [6,2,8,5,9,4] with first element being today\u2019s value then min value is 2 and it is present 1 days before today. Hence, ts_arg_min(x, d) = 1  \n"
  },
  {
    "name": "ts_regression",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_regression(y, x, d, lag = 0, rettype = 0)",
    "description": "Returns various parameters related to regression function",
    "documentation": "/operators/ts_regression",
    "level": "ALL",
    "summary": "**ts_regression(y, x, d, lag = 0, rettype = 0)**  Given a set of two variables\u2019 values (X: the independent variable, Y: the dependent variable) over a course of d days, an approximating linear function can be defined, such that sum of squared errors on this set assumes minimal value:  \nBeta and Alpha in second line are OLS Linear Regression coefficients.  ts_regression operator returns various parameters related to said regression. This is governed by \u201crettype\u201d keyword argument, which has a default value of 0. Other \u201crettype\u201d argument values correspond to:  \nHere, \"di\" is current day index, \u201cn\u201d(may differ from d) is a number of valid (x, y) tuples used for calculation. All summations are over day index, using only valid tuples.  \u201clag\u201d keyword argument may be optionally specified (default value is zero) to calculate lagged regression parameters instead:  \nExample:    *     * ts_regression(est_netprofit, est_netdebt, 252, lag = 0, rettype = 2)       * Taking the data from the past 252 trading days (1 year), return the \u03b2 coefficient from the equation when estimating the est_netprofit using the est_netdebt  \nAlpha Expression:\nts_regression(ts_mean(volume,2),ts_returns(close,2),252)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: MARKET\nTruncation: 5.0\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "kth_element",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "kth_element(x, d, k)",
    "description": "Returns K-th value of input by looking through lookback days. This operator can be used to backfill missing data if k=1",
    "documentation": "/operators/kth_element",
    "level": "ALL",
    "summary": "Returns k-th value of input by looking through lookback days while ignoring space separated scalars in ignore list. This operator is also known as **backfill** operator as it can be used to backfill missing data.  **ignore** parameter is used to provide list of separated scalars to ignore from counting    **Example of backfill:**  \nAlpha Expression:\nkth_element(sales/assets,252,k=\"1\",ignore=\"NAN0\")\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: INDUSTRY\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "hump",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "hump(x, hump = 0.01)",
    "description": "Limits amount and magnitude of changes in input (thus reducing turnover)",
    "documentation": "/operators/hump",
    "level": "ALL",
    "summary": "**hump(x, hump = 0.01)**  This operator limits the frequency and magnitude of changes in the Alpha (thus reducing turnover). If today's values show only a minor change (not exceeding the Threshold) from yesterday's value, the output of the hump operator stays the same as yesterday. If the change is bigger than the limit, the output is yesterday's value plus the limit in the direction of the change.  This operator may help reduce turnover and drawdown.  Flowchart of the Hump operator:  \nAlpha Expression:\nhump(-ts_delta(close,5),hump=0.00001)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: MARKET\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "ts_delta",
    "category": "Time Series",
    "scope": [
      "REGULAR"
    ],
    "definition": "ts_delta(x, d)",
    "description": "Returns x - ts_delay(x, d)",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "winsorize",
    "category": "Cross Sectional",
    "scope": [
      "REGULAR"
    ],
    "definition": "winsorize(x, std=4)",
    "description": "Winsorizes x to make sure that all values in x are between the lower and upper limits, which are specified as multiple of std.",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "rank",
    "category": "Cross Sectional",
    "scope": [
      "REGULAR"
    ],
    "definition": "rank(x, rate=2)",
    "description": "Ranks the input among all the instruments and returns an equally distributed number between 0.0 and 1.0. For precise sort, use the rate as 0",
    "documentation": "/operators/rank",
    "level": "ALL",
    "summary": "rank(x, rate=2):  The Rank operator ranks the value of the input data x for the given stock among all instruments, and returns float numbers equally distributed between 0.0 and 1.0. When rate is set to 0, the sorting is done precisely. The default value of rate is 2.  This operator may help reduce outliers and drawdown while improving the Sharpe.  **Example:**  Rank(close); Rank (close, rate=0) # Sorts precisely  X = (4,3,6,10,2) => Rank(x) = (0.5, 0.25, 0.75, 1, 0)  \n"
  },
  {
    "name": "vector_neut",
    "category": "Cross Sectional",
    "scope": [
      "REGULAR"
    ],
    "definition": "vector_neut(x, y)",
    "description": "For given vectors x and y, it finds a new vector x* (output) such that x* is orthogonal to y",
    "documentation": "/operators/vector_neut",
    "level": null,
    "summary": "vector_neut(x,y)  Input1 neutralize to input2  For given vector A (i.e., input1) and B (i.e., input2), it finds a new vector A' (i.e., output) such that A' is orthogonal to B. It calculates projection of A onto B, and then subtracts projection vector from A to find the rejection vector (i.e., A') which is perpendicular to the B.  This operator may help reduce correlation, depending on the neutralization used.  **Example** :  \nAlpha Expression:\nvector_neut(open,close)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: INDUSTRY\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "zscore",
    "category": "Cross Sectional",
    "scope": [
      "REGULAR"
    ],
    "definition": "zscore(x)",
    "description": "Z-score is a numerical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean",
    "documentation": "/operators/zscore",
    "level": "ALL",
    "summary": "**zscore(x)**  \nZ-score is a statistical tool that indicates how many standard deviations a data point lies from the average of a group of values. Essentially, it measures how unusual a data point is in relation to the mean, making it a handy tool for understanding deviation and comparison.  The formula to calculate a Z-score is:  \nWhere:    * x is an individual data point   * mean(x) is the average of the data set   * std(x) is the standard deviation of the data set  By this definition, the mean of the Z-scores in a distribution is always 0, and the standard deviation is always 1.  A Z-score tells you how many standard deviations a particular data point is from the mean. If the Z-score is positive, the data point is above the mean, and if it's negative, it's below the mean.  Z-scores may be especially useful for normalizing and comparing different data fields for different stocks or different data fields. They allow researchers to calculate the probability of a score occurring within a standard normal distribution and compare two scores that are from different samples (which may have different means and standard deviations).  This operator may help reduce outliers.  \nAlpha Expression:\nzscore(close)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: MARKET\nTruncation: 0.03\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "scale",
    "category": "Cross Sectional",
    "scope": [
      "REGULAR"
    ],
    "definition": "scale(x, scale=1, longscale=1, shortscale=1)",
    "description": "Scales input to booksize. We can also scale the long positions and short positions to separate scales by mentioning additional parameters to the operator",
    "documentation": "/operators/scale",
    "level": "ALL",
    "summary": "scale (x, scale=1, longscale=1, shortscale=1)  The operator scales the input to the book size. We can optionally tune the book size by specifying the additional parameter 'scale=booksize_value'. We can also scale the long positions and short positions to separate scales by specifying additional parameters: longscale=long_booksize and shortscale=short_booksize. The default value of each leg of the scale is 0, which means no scaling, unless specified otherwise. Scale the alpha so that the sum of abs(x) over all instruments equals 1. To scale to a different book size, use Scale(x) * booksize.  This operator may help reduce outliers.  Please check examples for the application of the same  **Examples** :  scale(returns, scale=4); scale (returns, scale= 1) + scale (close, scale=20); scale (returns, longscale=4, shortscale=3)  \n"
  },
  {
    "name": "normalize",
    "category": "Cross Sectional",
    "scope": [
      "REGULAR"
    ],
    "definition": "normalize(x, useStd = false, limit = 0.0)",
    "description": "Calculates the mean value of all valid alpha values for a certain date, then subtracts that mean from each element",
    "documentation": "/operators/normalize",
    "level": "ALL",
    "summary": "**normalize(x, useStd = false, limit = 0.0)**  \nThis operator calculates the mean value of all valid alpha values for a certain date, then subtracts that mean from each element. If useStd= true, the operator calculates the standard deviation of the resulting values and divides each normalized element by it. If limit is not equal to 0.0, operator puts the limit of the resulting alpha values (between -limit to + limit).   Example:   If for a certain date, instrument value of certain input x is [3,5,6,2], mean = 4 and standard deviation = 1.82   normalize(x, useStd = false, limit = 0.0) = [3-4,5-4,6-4,2-4] = [-1,1,2,-2]   normalize(x, useStd = true, limit = 0.0) = [-1/1.82,1/1.82,2/1.82,-2/1.82] = [-0.55,0.55,1.1,-1.1]  \n"
  },
  {
    "name": "quantile",
    "category": "Cross Sectional",
    "scope": [
      "REGULAR"
    ],
    "definition": "quantile(x, driver = gaussian, sigma = 1.0)",
    "description": "Rank the raw vector, shift the ranked Alpha vector, apply distribution (gaussian, cauchy, uniform). If driver is uniform, it simply subtract each Alpha value with the mean of all Alpha values in the Alpha vector",
    "documentation": "/operators/quantile",
    "level": "ALL",
    "summary": "**quantile(x, driver = gaussian, sigma = 1.0)**  \nRank the input raw Alpha vector   The ranked Alpha value would be within [0, 1]    1. Shift the ranked Alpha vector   For every Alpha value in the ranked Alpha vector, it is shifted as: Alpha_value = 1/N + Alpha_value * (1 - 2/N), here assume there are N instruments with value in the Alpha vector. The shifted Alpha value would be within [1/N, 1-1/N]    2. Apply distribution for each Alpha value in the ranked Alpha vector using the specified driver. Driver can be one of \"gaussian\", \"uniform\", \"cauchy\".  Note : Sigma only affects the scale of the final value.  This operator may help reduce outliers.  **Example** :  \nAlpha Expression:\nquantile(close,driver=gaussian,sigma=0.5)\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 3\nNeutralization: MARKET\nTruncation: 0.01\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "vec_sum",
    "category": "Vector",
    "scope": [
      "REGULAR"
    ],
    "definition": "vec_sum(x)",
    "description": "Sum of vector field x",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "vec_avg",
    "category": "Vector",
    "scope": [
      "REGULAR"
    ],
    "definition": "vec_avg(x)",
    "description": "Taking mean of the vector field x",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "bucket",
    "category": "Transformational",
    "scope": [
      "REGULAR"
    ],
    "definition": "bucket(rank(x), range=\"0, 1, 0.1\" or buckets = \"2,5,6,7,10\")",
    "description": "Convert float values into indexes for user-specified buckets. Bucket is useful for creating group values, which can be passed to GROUP as input",
    "documentation": "/operators/bucket",
    "level": "ALL",
    "summary": "**Bucket**  Convert float values into indexes for user-specified buckets. Bucket is useful for creating group values, which can be passed to group operators as input.  If **buckets** are specified as \"num_1, num_2, \u2026, num_N\", it is converted into brackets consisting of [(num_1, num_2, idx_1), (num_2, num_3, idx_2), ..., (num_N-1, num_N, idx_N-1)]  Thus with buckets=\"2, 5, 6, 7, 10\", the vector \"-1, 3, 6, 8, 12\" becomes \"0, 1, 2, 4, 5\"  If **range** if specified as \"start, end, step\", it is converted into brackets consisting of [(start, start+step, idx_1), (start+step, start+2*step, idx_2), ..., (start+N*step, end, idx_N)].  Thus with range=\"0.1, 1, 0.1\", the vector \"0.05, 0.5, 0.9\" becomes \"0, 4, 8\"  Note that two hidden buckets corresponding to (-inf, start] and [end, +inf) are added by default. Use the **skipBegin** , **skipEnd** parameters to remove these buckets. Use **skipBoth** to set both **skipEnd** and **skipBegin** to true.  If you want to assign all NAN values into a separate group of their own, use **NANGroup**. The index value will be one after the last bucket  **Examples:**  my_group = bucket(rank(volume), range=\"0.1,1,0.1\");  group_neutralize(sales/assets, my_group)  my_group = bucket(rank(volume), buckets =\"0.2,0.5,0.7\", skipBoth=True, NANGroup=True);  group_neutralize(sales/assets, my_group)  \n"
  },
  {
    "name": "trade_when",
    "category": "Transformational",
    "scope": [
      "REGULAR"
    ],
    "definition": "trade_when(x, y, z)",
    "description": "Used in order to change Alpha values only under a specified condition and to hold Alpha values in other cases. It also allows to close Alpha positions (assign NaN values) under a specified condition",
    "documentation": "/operators/trade_when",
    "level": "ALL",
    "summary": "This operator can be used to change Alpha values only under a specified condition and to retain Alpha values in other cases. It also allows for closing Alpha positions (assigning NaN values) under a specified condition.  Trade_When (x=triggerTradeExp, y=AlphaExp, z=triggerExitExp)  If triggerExitExp > 0, Alpha = NaN.  Else if triggerTradeExp > 0, Alpha = AlphaExp;  else, Alpha = previousAlpha  This operator may help reduce correlation and reduce turnover.  **Examples:**  Trade_When (volume >= ts_sum(volume,5)/5, rank(-returns), -1)  If (volume >= ts_sum(volume,5)/5), Alpha = rank(-returns);  else trade previous Alpha;  exit condition is always false.  Trade_When (volume >= ts_sum(volume,5)/5, rank(-returns), abs(returns) > 0.1)  If abs(returns) > 0.1, Alpha = nan;  else if volume >= ts_sum(volume,5)/5, Alpha = rank(-returns);  else trade previous Alpha.  \n"
  },
  {
    "name": "group_mean",
    "category": "Group",
    "scope": [
      "REGULAR"
    ],
    "definition": "group_mean(x, weight, group)",
    "description": "All elements in group equals to the mean",
    "documentation": "/operators/group_mean",
    "level": "ALL",
    "summary": "group_mean(x, group) operator can be used to calculate harmonic mean of datafields. Harmonic mean gives equal weight to each value in terms of their reciprocal contribution and is considered a better method for calculating average for fundamental ratios and factors. For example, Harmonic mean of P/E ratio (price-to-earnings) for an industry can be calculated as:  \nAlpha Expression:\n1/(group_mean(eps/close,1,industry))\nSimulation Settings:\nRegion: USA\nUniverse: TOP3000\nDelay: 1\nDecay: 1\nNeutralization: MARKET\nTruncation: 1.0\nPasteurization: ON\nNaN Handling: OFF\n"
  },
  {
    "name": "group_rank",
    "category": "Group",
    "scope": [
      "REGULAR"
    ],
    "definition": "group_rank(x, group)",
    "description": "Each elements in a group is assigned the corresponding rank in this group",
    "documentation": "/operators/group_rank",
    "level": "ALL",
    "summary": "**group_rank(x, group)**  \nGroup operators are a type of cross-sectional operator that compares stocks at a finer level, where the cross-sectional operation is applied within each group, rather than across the entire market. The group_rank operator allocates the stocks to their specified group, then within each group, it ranks the stocks based on their input value for data field x and returns an equally distributed number between 0.0 and 1.0.  This operator may help reduce both outliers and drawdown while reducing correlation.  **Example:** group_rank(x, subindustry)    * The stocks are first grouped into their respective subindustry.   * Within each subindustry, the stocks within that subindustry are ranked based on their input value for data field x and assigned an equally distributed number between 0.0 and 1.0.  \n"
  },
  {
    "name": "group_backfill",
    "category": "Group",
    "scope": [
      "REGULAR"
    ],
    "definition": "group_backfill(x, group, d, std = 4.0)",
    "description": "If a certain value for a certain date and instrument is NaN, from the set of same group instruments, calculate winsorized mean of all non-NaN values over last d days",
    "documentation": "/operators/group_backfill",
    "level": "ALL",
    "summary": "**group_backfill(x, group, d, std = 4.0)**  \nIf a certain value for a certain date and instrument is NaN, from the set of same group instruments, calculate winsorized mean of all non-NaN values over last d days. Winsorized mean means inputs are truncated by std * stddev where stddev is the standard deviation of inputs.    **Example:**   If d = 4 and there are 3 instruments(i1, i2, i3) in a group whose values for past 4 days are x[i1] = [4,2,5,5], x[i2] = [7,NaN,2,9], x[i3] = [NaN,-4,2,NaN] where first element is most recent, then if we want to backfill x, we will only have to backfill x[i3]\u2019s first element because every other instrument\u2019s first element is non-NaN.  The non-NaN values of other groups are [4,2,5,5,7,2,9,-4,2]. Mean = 3.56, Standard deviation is 3.71 and none of the item is outside the range of 3.56 \u2013 4 * 3.71 and 3.56 + 4 * 3.71. Hence, we don\u2019t need to clip elements to those limits. Hence, Winsorized mean = backfilled value = 3.56.  For three instruments, group_backfill(x, group, d, std = 4.0) = [4,7,3.56]  \n"
  },
  {
    "name": "group_scale",
    "category": "Group",
    "scope": [
      "REGULAR"
    ],
    "definition": "group_scale(x, group)",
    "description": "Normalizes the values in a group to be between 0 and 1. (x - groupmin) / (groupmax - groupmin)",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "group_zscore",
    "category": "Group",
    "scope": [
      "REGULAR"
    ],
    "definition": "group_zscore(x, group)",
    "description": "Calculates group Z-score - numerical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean. zscore = (data - mean) / stddev of x for each instrument within its group.",
    "documentation": null,
    "level": "ALL"
  },
  {
    "name": "group_neutralize",
    "category": "Group",
    "scope": [
      "REGULAR"
    ],
    "definition": "group_neutralize(x, group)",
    "description": "Neutralizes Alpha against groups. These groups can be subindustry, industry, sector, country or a constant",
    "documentation": "/operators/group_neutralize",
    "level": "ALL",
    "summary": "**group_neutralize(x, group)**  \nNeutralize alpha against groups. Difference between normalize and group_neutralize is in normalize, every element is subtracted by mean of all values of all instruments on that day whereas in group_neutralize, element is subtracted by mean of all values of the group of instruments that it belongs on that day.  This operator may help reduce correlation, depending on the neutralization used.  **Example:**   If values of field x on a certain date for 10 instruments is [3,2,6,5,8,9,1,4,8,0] and first 5 instruments belong to one group, last 5 belong to other, then mean of first group = (3+2+6+5+8)/5 = 4.8 and mean of second group = (9+1+4+8+0)/5 = 4.4. Subtracting means from instruments of respective groups gives [3-4.8, 2-4.8, 6-4.8, 5-4.8, 8-4.8, 9-4.4, 1-4.4, 4-4.4, 8-4.4, 0-4.4] = [-1.8, -2.8, 1.2, 0.2, 3.2, 4.6, -3.4, -0.4, 3.6, -4.4]  \n"
  }
]